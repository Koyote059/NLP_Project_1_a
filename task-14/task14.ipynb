{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gensim\n",
    "#%pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.stem import SnowballStemmer\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.json', encoding='utf-8') as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the JSON into a list of [[w1,w2,w3,w4,w5],solution] items\n",
    "datalist = [[list(d.values())[0:5], d['solution']] for d in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a italian word2vec model (https://mlunicampania.gitlab.io/italian-word2vec/)\n",
    "model = KeyedVectors.load(\"SG-300-W10N20E50/W2V.kv\", mmap='r+')\n",
    "\n",
    "# Save the words and their vectors\n",
    "vocabs = model.index_to_key \n",
    "vectors = model.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las siguientes palabras no están en 'vocabs': ['x men', 'fantastici 4', 'gran premio', '68', 'terra santa', 'san giovanni', 'new york', 'cin cin', 'de amicis', \"non c'è\", \"d'annunzio\", 'secondo tempo', 'terza età', 'totò e peppino']\n",
      "14 words are not in the vocabulary\n",
      "0.009333333333333334 % of the words are not in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Create a list for the words of our datalist that are not in the word2vec vocabulary\n",
    "not_in_vocabs = []\n",
    "\n",
    "# Check if all the words in datalist are in the vocabulary\n",
    "for sublist in datalist:\n",
    "    for word in sublist[0] + [sublist[1]]:\n",
    "        if word not in vocabs and word not in not_in_vocabs:\n",
    "            not_in_vocabs.append(word)\n",
    "\n",
    "# Print the words that are not in the vocabulary\n",
    "print(\"Las siguientes palabras no están en 'vocabs':\", not_in_vocabs)\n",
    "\n",
    "#Print how many words are not in the vocabulary\n",
    "print(len(not_in_vocabs), \"words are not in the vocabulary\")\n",
    "\n",
    "#Print the percentage of words that are not in the vocabulary\n",
    "print(len(not_in_vocabs)/(len(datalist)*5),\"% of the words are not in the vocabulary\")\n",
    "# As we can see, the percentage that are not in the vocabulary is very low, so we can ignore them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmer for italian words (to check if two words share the same root)\n",
    "stemmer = SnowballStemmer('italian')\n",
    "\n",
    "# Create an empty list to store all the JSON objects\n",
    "final_json = []\n",
    "\n",
    "for i in range(len(datalist)):\n",
    "\n",
    "    # Our 5 words\n",
    "    words = datalist[i][0].copy()\n",
    "\n",
    "    # Delete the words that are not in the italian vocabulary because we will not calculate the distractors with them.\n",
    "    # (We can do this because there is not any game that has more tha 1 not_in_vocabs word, so we will always have at least 4 words to calculate the distractors)\n",
    "    words = [word for word in words if word not in not_in_vocabs]\n",
    "    if len(words) < 4:\n",
    "        print(\"ALERT: Less than 4 words found in vocabulary\") # This never happens, \n",
    "\n",
    "    # Our 5 word and the solution. (This list will be used to avoid creating new distractors that are similar to the solution, the 5 words or the other distractors)\n",
    "    banned_words = words.copy()\n",
    "    banned_words.append(datalist[i][1])\n",
    "\n",
    "    # Create a list to store the distractors\n",
    "    distractor_list = []\n",
    "\n",
    "\n",
    "    for _ in range(3):\n",
    "        # Choose randomly between 2 and {len(words) - 1} words\n",
    "        random_index_list = random.sample(list(range(len(words))), random.randint(2, len(words) - 1))\n",
    "        random_words = [words[i] for i in random_index_list]\n",
    "\n",
    "        # Select embeeding vectors of chosen words\n",
    "        word_vectors = [vectors[vocabs.index(w)] for w in random_words]\n",
    "\n",
    "        # Sum the vectors\n",
    "        vector_sum = np.sum(word_vectors, axis=0)\n",
    "\n",
    "        # Find the most similar words to the sum vector in the vocabulary\n",
    "        similar_word = model.similar_by_vector(vector_sum, topn=20)\n",
    "\n",
    "        #Check that the possible new distractor have not the same root as the original words, the solution or the other distractors\n",
    "        selected_words = [w[0] for w in similar_word if all(stemmer.stem(w[0]) != stemmer.stem(bw) for bw in banned_words)]\n",
    "\n",
    "        # Check if selected_words is empty\n",
    "        if len(selected_words) == 0:\n",
    "            print(\"ALERT: No words found\") # This never happens\n",
    "        else:\n",
    "            # Add the word to the distractor list and the banned words list\n",
    "            distractor_list.append(selected_words[0])\n",
    "            banned_words.append(selected_words[0])\n",
    "\n",
    "    # Add the solution and the distractors to make the choices list\n",
    "    choices = distractor_list.copy()\n",
    "    choices.append(datalist[i][1])\n",
    "    \n",
    "    # Shuffle the choices list randomly\n",
    "    random.shuffle(choices)\n",
    "\n",
    "    # Find the index of the solution in the list\n",
    "    label = choices.index(datalist[i][1])\n",
    "    \n",
    "    # Add the JSON object to the final_json list\n",
    "    final_json.append({'w1': datalist[i][0][0], \n",
    "                     'w2': datalist[i][0][1], \n",
    "                     'w3': datalist[i][0][2], \n",
    "                     'w4': datalist[i][0][3], \n",
    "                     'w5': datalist[i][0][4], \n",
    "                     'choices': choices, \n",
    "                     'label': label})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the final list randomly\n",
    "random.shuffle(final_json)\n",
    "\n",
    "# Split the list into train and test\n",
    "split_index = int(0.8 * len(final_json))\n",
    "train_json = final_json[:split_index]\n",
    "test_json = final_json[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save both JSONLs \n",
    "\n",
    "with open('Ghigliottin-AI-task1-train-data.jsonl', 'w', encoding='utf-8') as file:\n",
    "    for dict in train_json:\n",
    "        json.dump(dict, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('Ghigliottin-AI-task1-test-data.jsonl', 'w', encoding='utf-8') as file:\n",
    "    for dict in test_json:\n",
    "        json.dump(dict, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list = [\n",
    "\"Given the following words: {w1}, {w2}, {w3}, {w4}, {w5}; and the list of choices: {choices}. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = []\n",
    "for data in train_json:\n",
    "    formatted_text = prompt_list[0].format(w1=data['w1'], w2=data['w2'], w3=data['w3'], w4=data['w4'], w5=data['w5'], choices=data['choices'])\n",
    "    input_prompts.append(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install replicate\n",
    "import os\n",
    "import replicate\n",
    "from getpass import getpass\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_BU4b7PNHgP3LHseHL2j43ia0HY6NZ604eCu20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_70b = \"replicate/llama-2-70b-chat:2c1608e18606fad2812020dc541930f2d0495ce32eee50074220b87300bc16e1\"\n",
    "llama2_13b = \"a16z-infra/llama-2-13b-chat:2a7f981751ec7fdf87b5b91ad4db53683a98082e9ff7bfd12c8cd5ea85980a52\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_outputs = []\n",
    "for prompt in input_prompts[0:5]:\n",
    "    output = replicate.run(\n",
    "        \"meta/llama-2-70b-chat\",\n",
    "        input={\n",
    "            \"prompt\": prompt,\n",
    "            \"system_prompt\": \"The first token of your answer must be one of these numbers (0,1,2,3).\",\n",
    "        },\n",
    "    )\n",
    "    prompt_outputs.append(''.join(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lables = []\n",
    "error_outputs = []\n",
    "for o in prompt_outputs:\n",
    "\n",
    "\n",
    "    match = re.search(r'[0-3]', o)\n",
    "\n",
    "    if match:\n",
    "        first_number = match.group()\n",
    "        output_lables.append(first_number)  # Output: '1'\n",
    "    else:\n",
    "        print(\"No number found in the string.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Given the following words: paese, vizio, marchio, incendio, nobile; and the list of choices: ['castello', 'casato', 'brand', 'origine']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: fiume, pesca, medicina, saggezza, filo; and the list of choices: ['perle', 'canapa', 'scienza', 'foce']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: mettere, tempesta, modesto, nuovo, garanzia; and the list of choices: ['avviso', 'compenso', 'finanziario', 'burrasca']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: pubblico, stretto, primo, entrare, radar; and the list of choices: ['entrarvi', 'sonar', 'missile', 'contatto']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: famiglia, chiudere, poco, vero, dreyfus; and the list of choices: ['affare', 'riaprire', 'affaire', 'infatti']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: anna, piazza, corte, campo, scienza; and the list of choices: ['piazzetta', 'miracoli', 'palazzo', 'maria']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: cane, pane, mettere, pulizia, sciabola; and the list of choices: ['spada', 'mangiare', 'denti', 'coltello']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: letto, qualità, servizi, urbano, spesa; and the list of choices: ['pubblici', 'sanitari', 'extra', 'infrastrutture']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: partita, onore, compagnia, orizzonte, presa; and the list of choices: ['giro', 'giocata', 'sfida', 'squadra']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\",\n",
       " \"Given the following words: terra, dolore, perdere, punta, sotto; and the list of choices: ['pancia', 'estremità', 'cadere', 'sofferenza']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\"]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The answer is:\\n\\n2',\n",
       " 'The answer is:\\n\\n2\\n\\nThe choice related to all the 5 words is \"scienza\".',\n",
       " 'The answer is:\\n\\n2',\n",
       " 'The answer is:\\n\\n2. missile',\n",
       " 'The answer is:\\n\\n2',\n",
       " 'The answer is:\\n\\n2',\n",
       " \"The answer is:\\n\\n2. 'coltello'\",\n",
       " 'The answer is:\\n\\n2',\n",
       " 'The answer is:\\n\\n2\\n\\nThe choice \"sfida\" is related to all the 5 words:\\n\\n* \"Partita\" means \"game\" in Italian, and a game can be a challenge or a sfida.\\n* \"Onore\" means \"honor\" in Italian, and a person\\'s honor can be challenged or put to the test in a sfida.\\n* \"Compagnia\" means \"company\" in Italian, and a company can face challenges or sfide in its business operations.\\n* \"Orizzonte\" means \"horizon\" in Italian',\n",
       " 'The answer is:\\n\\n2\\n\\nThe choice \"cadere\" is related to all the 5 words:\\n\\n* \"Terra\" can be translated as \"land\" or \"earth\", and \"cadere\" means \"to fall\".\\n* \"Dolore\" means \"pain\", and \"cadere\" can be used to describe a painful sensation.\\n* \"Perdere\" means \"to lose\", and \"cadere\" can be used to describe something that is lost or fallen.\\n* \"Punta\" means \"point\", and \"']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '2', '2', '2', '2', '2', '2', '2', '2', '2']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gpt4all\n",
    "#%pip install langchain\n",
    "# Import dependencies\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "#from langchain.llms import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(\"orca-mini-3b-gguf2-q4_0.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_prompts[0], max_tokens=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Given the following words: paese, vizio, marchio, incendio, nobile; and the list of choices: ['castello', 'casato', 'brand', 'origine']. Which choice is related to all the 5 words? Please answer only with the index of the choice in the list\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "## Specify model weights path\n",
    "#PATH='./nous-hermes-13b.ggmlv3.q4_0.bin'\n",
    "#\n",
    "## Create LLM Class\n",
    "#llm = GPT4All(model=PATH, verbose=True)\n",
    "#\n",
    "## Create a prompt template\n",
    "#prompt = PromptTemplate(\n",
    "#    input_variables=['instruction', 'input', 'response'],\n",
    "#    template=\"\"\"\n",
    "#    ### Instruction:\n",
    "#    {instruction}\n",
    "#    ### Input:\n",
    "#    {input}\n",
    "#    ### Response:\n",
    "#    {response}\n",
    "#    \"\"\" )\n",
    "#\n",
    "#chain = LLMChain(prompt=prompt, llm=llm)\n",
    "#\n",
    "## Run the prompt\n",
    "## I used a childen story to test https://cuentosparadormir.com/infantiles/cuento/barba-flamenco-y-el-recortador-de-cuentos\n",
    "## its about 783 words long!\n",
    "#chain.run(instruction=\"\"\"Resume esta historia, hazlo en español\"\"\",\n",
    "#input=\"\"\"[...story content...]\"\"\",\n",
    "#response='A: ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
